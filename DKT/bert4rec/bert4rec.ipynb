{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.29.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert4Rec을 이용한 DKT 예측 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import sigmoid\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "import pytz\n",
    "import argparse\n",
    "import math\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## args 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"--seed\", default=42, type=int, help=\"seed\")\n",
    "    parser.add_argument(\"--device\", default=\"cpu\", type=str, help=\"cpu or gpu\")\n",
    "\n",
    "    parser.add_argument(\"--data_path\", default=\"/opt/ml/input/data/\", type=str, help=\"data directory\")\n",
    "    parser.add_argument(\"--asset_dir\", default=\"asset/\", type=str, help=\"data directory\")\n",
    "    parser.add_argument(\"--model_dir\", default=\"models/\", type=str, help=\"model directory\")\n",
    "    parser.add_argument(\n",
    "        \"--file_name\", default=\"train_data.csv\", type=str, help=\"train file name\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\"--num_workers\", default=1, type=int, help=\"number of workers\")\n",
    "\n",
    "\n",
    "    # 훈련\n",
    "    parser.add_argument(\"--n_epochs\", default=20, type=int, help=\"number of epochs\")\n",
    "    parser.add_argument(\"--batch_size\", default=64, type=int, help=\"batch size\")\n",
    "    parser.add_argument(\"--lr\", default=0.0001, type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\"--clip_grad\", default=10, type=int, help=\"clip grad\")\n",
    "    parser.add_argument(\"--patience\", default=5, type=int, help=\"for early stopping\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--log_steps\", default=50, type=int, help=\"print log per n steps\"\n",
    "    )\n",
    "\n",
    "    # BERT params - 개인적으로 하이퍼파라미터 튜닝\n",
    "    parser.add_argument('--bert_max_len', type=int, default=13, help='Length of sequence for bert')\n",
    "    parser.add_argument('--bert_num_items', type=int, default=9454, help='Number of total items') #assessmentid 수\n",
    "    parser.add_argument('--bert_num_tags', type=int, default=912, help='Number of total items') #knowledgetag 수\n",
    "    parser.add_argument('--bert_hidden_units', type=int, default=64, help='Size of hidden vectors (d_model)')\n",
    "    parser.add_argument('--bert_num_blocks', type=int, default=2, help='Number of transformer layers')\n",
    "    parser.add_argument('--bert_num_heads', type=int, default=2, help='Number of heads for multi-attention')\n",
    "    parser.add_argument('--bert_dropout', type=float, default=0.2, help='Dropout probability to use throughout the model')\n",
    "    parser.add_argument('--bert_mask_prob', type=float, default=0.1, help='Probability for masking items in the training sequence')\n",
    "\n",
    "    # optimizer #\n",
    "    parser.add_argument('--optimizer', type=str, default='Adam', choices=['Adam', 'AdamW'])\n",
    "    parser.add_argument('--scheduler', type=str, default=\"plateau\", help=\"scheduler type\")\n",
    "    parser.add_argument('--weight_decay', type=float, default=0, help='l2 regularization')\n",
    "    parser.add_argument('--momentum', type=float, default=None, help='SGD momentum')\n",
    "    # lr scheduler #\n",
    "    parser.add_argument('--decay_step', type=int, default=15, help='Decay step for StepLR')\n",
    "    parser.add_argument('--gamma', type=float, default=0.1, help='Gamma for StepLR')\n",
    "    \n",
    "    args = parser.parse_args('')\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(logger_conf: dict):\n",
    "    import logging\n",
    "    import logging.config\n",
    "\n",
    "    logging.config.dictConfig(logger_conf)\n",
    "    logger = logging.getLogger()\n",
    "    return logger\n",
    "\n",
    "logging_conf = {  # only used when 'user_wandb==False'\n",
    "    \"version\": 1,\n",
    "    \"formatters\": {\n",
    "        \"basic\": {\"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"}\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"basic\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "        },\n",
    "        \"file_handler\": {\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"level\": \"DEBUG\",\n",
    "            \"formatter\": \"basic\",\n",
    "            \"filename\": \"run.log\",\n",
    "        },\n",
    "    },\n",
    "    \"root\": {\"level\": \"INFO\", \"handlers\": [\"console\", \"file_handler\"]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data path 설정\n",
    "data_dir = \"/opt/ml/input/data/\"\n",
    "train_path = \"train_data.csv\"\n",
    "test_path = \"test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Bert:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.train_data\n",
    "\n",
    "    def get_test_data(self):\n",
    "        return self.test_data\n",
    "\n",
    "    ### train / valid split을 위한 함수\n",
    "    def split_data(self,\n",
    "                   data: np.ndarray,\n",
    "                   ratio: float = 0.8,\n",
    "                   shuffle: bool = True,\n",
    "                   seed: int = 0) -> Tuple[np.ndarray]:\n",
    "        \"\"\"\n",
    "        split data into two parts with a given ratio.\n",
    "        \"\"\"\n",
    "        if shuffle:\n",
    "            random.seed(seed)  # fix to default seed 0\n",
    "            random.shuffle(data)\n",
    "\n",
    "        size = int(len(data) * ratio)\n",
    "        data_1 = data[:size]\n",
    "        data_2 = data[size:]\n",
    "        return data_1, data_2\n",
    "\n",
    "    def __save_labels(self, encoder: LabelEncoder, name: str) -> None:\n",
    "        le_path = os.path.join(self.args.asset_dir, name + \"_classes.npy\")\n",
    "        np.save(le_path, encoder.classes_)\n",
    "\n",
    "    def __preprocessing(self, df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "        #범주형 변수 label encoding\n",
    "        categories_lst = [\"assessmentItemID\", \"testId\", \"KnowledgeTag\"]\n",
    "\n",
    "        #label saving을 위해서 필요\n",
    "        if not os.path.exists(self.args.asset_dir):\n",
    "            os.makedirs(self.args.asset_dir)\n",
    "\n",
    "        for col in categories_lst:\n",
    "            encoder = LabelEncoder()\n",
    "            if is_train:\n",
    "                # For UNKNOWN class\n",
    "                cat = df[col].unique().tolist() + [\"unknown\"]\n",
    "                encoder.fit(cat)\n",
    "                self.__save_labels(encoder, col)\n",
    "            else:\n",
    "                label_path = os.path.join(self.args.asset_dir, col + \"_classes.npy\")\n",
    "                encoder.classes_ = np.load(label_path)\n",
    "\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: x if str(x) in encoder.classes_ else \"unknown\"\n",
    "                )\n",
    "\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = encoder.transform(df[col])\n",
    "\n",
    "        def convert_time(s: str):\n",
    "            timestamp = time.mktime(\n",
    "                datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple()\n",
    "            )\n",
    "            return int(timestamp)\n",
    "\n",
    "        df[\"Timestamp\"] = df[\"Timestamp\"].apply(convert_time)\n",
    "\n",
    "        # 같은 문제를 여러번 푼 경우 마지막만 반영되도록 정리\n",
    "\n",
    "        # userid와 assessmentItemID 기준으로 그룹화한다.\n",
    "        grouped = df.groupby(['userID', 'assessmentItemID'])\n",
    "        #각 그룹별로 동일 문제를 몇 번 푸는지를 계산하고, 이를 맵핑할 딕셔너리를 만든다. ex) {(0, 'A020172001'): 1, ...}\n",
    "        counts_dict = grouped.size().to_dict()\n",
    "        # counts_dict를 이용하여 assessmentItemID별로 푼 문제 수를 맵핑한다.\n",
    "        df['#ofsameSolved'] = df.set_index(['userID', 'assessmentItemID']).index.map(counts_dict) \n",
    "\n",
    "        df = df.sort_values(by=['userID', 'assessmentItemID', 'Timestamp'], ascending=[True, True, True])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        df.drop(df.loc[df['#ofsameSolved'] == 2].iloc[::2].index, axis = 0, inplace=True)  \n",
    "        df.drop(df.loc[df['#ofsameSolved'] == 3].iloc[::3].index, axis = 0, inplace=True)\n",
    "        df.drop(df.loc[df['#ofsameSolved'] == 3].iloc[::2].index, axis = 0, inplace=True)\n",
    "        df.drop(columns='#ofsameSolved', axis = 1, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # def __feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    #     \n",
    "    #     return df\n",
    "\n",
    "    def load_data_from_file(self, file_name: str, is_train: bool = True) -> np.ndarray:\n",
    "        csv_file_path = os.path.join(self.args.data_path, file_name)\n",
    "        df = pd.read_csv(csv_file_path)  # , nrows=100000)\n",
    "        #df = self.__feature_engineering(df)\n",
    "        df = self.__preprocessing(df, is_train)\n",
    "\n",
    "        # 추후 feature를 embedding할 시에 embedding_layer의 input 크기를 결정할때 사용\n",
    "        self.args.n_questions = len(\n",
    "            np.load(os.path.join(self.args.asset_dir, \"assessmentItemID_classes.npy\"))\n",
    "        )\n",
    "        self.args.n_tests = len(\n",
    "            np.load(os.path.join(self.args.asset_dir, \"testId_classes.npy\"))\n",
    "        )\n",
    "        self.args.n_tags = len(\n",
    "            np.load(os.path.join(self.args.asset_dir, \"KnowledgeTag_classes.npy\"))\n",
    "        )\n",
    "\n",
    "        df = df.sort_values(by=[\"userID\", \"Timestamp\"], axis=0)\n",
    "        columns = [\"userID\", \"assessmentItemID\", \"testId\", \"answerCode\", \"KnowledgeTag\"]\n",
    "        #userID와 testId로 groupby진행: 세션 단위 시퀀스 모델\n",
    "        group = (\n",
    "            df[columns]\n",
    "            .groupby([\"userID\", \"testId\"])\n",
    "            .apply(\n",
    "                lambda r: (\n",
    "                    r[\"assessmentItemID\"].values,\n",
    "                    r[\"KnowledgeTag\"].values,\n",
    "                    r[\"answerCode\"].values,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        return group.values\n",
    "\n",
    "    def load_train_data(self, file_name: str) -> None:\n",
    "        self.train_data = self.load_data_from_file(file_name)\n",
    "\n",
    "    def load_test_data(self, file_name: str) -> None:\n",
    "        self.test_data = self.load_data_from_file(file_name, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKTDataset_Bert(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: np.ndarray, args):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        row = self.data[index]\n",
    "        \n",
    "        # Load from data : mask된 값을 0으로 처리하기 위해 1을 더해줌\n",
    "        question, tag, correct = row[0], row[1], row[2]\n",
    "        data = {\n",
    "            \"question\": torch.tensor(question + 1, dtype=torch.int),\n",
    "            \"tag\": torch.tensor(tag + 1, dtype=torch.int),\n",
    "            \"correct\": torch.tensor(correct, dtype=torch.int),\n",
    "        }\n",
    "\n",
    "        # Generate mask \n",
    "        seq_len = len(row[0])\n",
    "        for k, seq in data.items():\n",
    "            # Pre-padding non-valid sequences\n",
    "            tmp = torch.zeros(13) #하나의 시험지의 최대 길이 13\n",
    "            tmp[13-seq_len:] = data[k]\n",
    "            data[k] = tmp\n",
    "        mask = torch.zeros(13, dtype=torch.int16)\n",
    "        mask[-seq_len:] = 1\n",
    "        data[\"mask\"] = mask\n",
    "        \n",
    "        # Generate interaction\n",
    "        interaction = data[\"correct\"] + 1  # 패딩을 위해 correct값에 1을 더해준다.\n",
    "        interaction = interaction.roll(shifts=1)\n",
    "        interaction_mask = data[\"mask\"].roll(shifts=1)\n",
    "        interaction_mask[0] = 0\n",
    "        interaction = (interaction * interaction_mask).to(torch.int64)\n",
    "        data[\"interaction\"] = interaction\n",
    "        data = {k: v.int() for k, v in data.items()}\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(args, train: np.ndarray, valid: np.ndarray) -> Tuple[torch.utils.data.DataLoader]:\n",
    "    pin_memory = False\n",
    "    train_loader, valid_loader = None, None\n",
    "\n",
    "    if train is not None:\n",
    "        trainset = DKTDataset_Bert(train, args)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            num_workers=args.num_workers,\n",
    "            shuffle=True,\n",
    "            batch_size=args.batch_size,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "    if valid is not None:\n",
    "        valset = DKTDataset_Bert(valid, args)\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            valset,\n",
    "            num_workers=args.num_workers,\n",
    "            shuffle=False,\n",
    "            batch_size=args.batch_size,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "preprocess = Preprocess_Bert(args)\n",
    "preprocess.load_train_data(file_name=args.file_name)\n",
    "train_data: np.ndarray = preprocess.get_train_data()\n",
    "train_data, valid_data = preprocess.split_data(data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292131"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73033"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(array([8891, 8892, 8893, 8894, 8895, 8896, 8897, 8898]), array([768, 768, 769, 767, 767, 770, 770, 770]), array([1, 0, 0, 0, 0, 0, 1, 0])),\n",
       "       (array([3532, 3533, 3534, 3535, 3536]), array([205, 205, 205, 205, 205]), array([1, 0, 0, 0, 0])),\n",
       "       (array([1525, 1526, 1528, 1527, 1529]), array([724, 724, 724, 724, 724]), array([1, 1, 1, 1, 0])),\n",
       "       ...,\n",
       "       (array([3948, 3949, 3950, 3951, 3952]), array([229, 228, 228, 229, 229]), array([1, 1, 1, 1, 1])),\n",
       "       (array([616, 617, 618, 619, 620]), array([601, 601, 601, 601, 601]), array([1, 1, 1, 1, 1])),\n",
       "       (array([8939, 8940, 8941, 8942, 8943, 8944, 8945, 8946]), array([426, 426,   7, 671, 671, 671, 426, 426]), array([0, 1, 1, 1, 1, 1, 1, 0]))],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert4rec 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert token embedding\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embed_size=512):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    "#bert positional embedding\n",
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        return self.pe.weight.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    \n",
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, max_len, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
    "        self.position = PositionalEmbedding(max_len=max_len, d_model=embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        x = self.token(sequence) + self.position(sequence)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformer layer\n",
    "1. multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single attention : attention 수식 구현\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Compute 'Scaled Dot Product Attention\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "    \n",
    "\n",
    "#multihead attention\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Take in model size and number of heads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "                             for l, x in zip(self.linear_layers, (query, key, value))]\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "\n",
    "        return self.output_linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. pointwise feedforward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert uses gelu instead of relu\n",
    "class GELU(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.activation(self.w_1(x))))\n",
    "    \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "#residual connection\n",
    "class SublayerConnection(nn.Module):\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformer block 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Encoder = Transformer (self-attention)\n",
    "    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
    "        \"\"\"\n",
    "        :param hidden: hidden size of transformer\n",
    "        :param attn_heads: head sizes of multi-head attention\n",
    "        :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_size\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed: int = 42):\n",
    "    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        set_seeds(args.seed)\n",
    "        # self.init_weights()\n",
    "        \n",
    "        max_len = args.bert_max_len\n",
    "        num_items = args.bert_num_items\n",
    "        n_tags = args.bert_num_tags\n",
    "        n_layers = args.bert_num_blocks\n",
    "        heads = args.bert_num_heads\n",
    "        hidden = args.bert_hidden_units\n",
    "        self.hidden = hidden\n",
    "        dropout = args.bert_dropout\n",
    "\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "\n",
    "        # self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=self.hidden, max_len=max_len, dropout=dropout)\n",
    "        # hd, intd = hidden, hidden // 3\n",
    "        # self.embedding_interaction = nn.Embedding(3, intd) # interaction은 현재 correct로 구성되어있다. correct(1, 2) + padding(0)\n",
    "        # self.embedding_question = nn.Embedding(num_items + 1, intd)\n",
    "        # self.embedding_tag = nn.Embedding(n_tags + 1, intd)\n",
    "\n",
    "        self.embedding_interaction = BERTEmbedding(vocab_size=3, embed_size=self.hidden, max_len = max_len, dropout=dropout)\n",
    "        self.embedding_question = BERTEmbedding(vocab_size=num_items + 1, embed_size=self.hidden, max_len = max_len, dropout=dropout)\n",
    "        self.embedding_tag = BERTEmbedding(vocab_size=n_tags + 1, embed_size=self.hidden, max_len = max_len, dropout=dropout)\n",
    "\n",
    "        # Concatentaed Embedding Projection\n",
    "        self.comb_proj = nn.Linear(self.hidden * 3, self.hidden)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.hidden, 1)\n",
    "\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(hidden, heads, hidden * 4, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    ## 수정 ##\n",
    "    def forward(self, question, tag, correct, mask, interaction):\n",
    "        batch_size = interaction.size(0)\n",
    "        # Embedding\n",
    "        embed_interaction = self.embedding_interaction(interaction.int())\n",
    "        embed_question = self.embedding_question(question.int())\n",
    "        embed_tag = self.embedding_tag(tag.int())\n",
    "        embed = torch.cat(\n",
    "            [\n",
    "                embed_interaction,\n",
    "                embed_question,\n",
    "                embed_tag,\n",
    "            ],\n",
    "            dim=2,\n",
    "        )\n",
    "        \n",
    "        X = self.comb_proj(embed)\n",
    "\n",
    "        mask = mask.unsqueeze(1).repeat(1, X.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        # running over multiple transformer blocks\n",
    "        for transformer in self.transformer_blocks:\n",
    "            X = transformer.forward(X, mask)\n",
    "\n",
    "        encoded_layers = X\n",
    "        # out = encoded_layers[0]\n",
    "        # out = out.contiguous().view(batch_size, -1, self.hidden)\n",
    "\n",
    "        out = encoded_layers\n",
    "        out = self.fc(out).view(batch_size, -1)\n",
    "        return out\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "        self.args = args\n",
    "        self.bert = BERT(args)\n",
    "        self.out = nn.Linear(self.bert.hidden, args.num_items + 1)\n",
    "\n",
    "    def code(cls):\n",
    "        return 'bert'\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimzer, scheduler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "\n",
    "def get_optimizer(model: torch.nn.Module, args):\n",
    "    if args.optimizer == \"Adam\":\n",
    "        optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=0.01)\n",
    "        \n",
    "    elif args.optimizer == \"AdamW\":\n",
    "        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=0.01)\n",
    "    # 모든 parameter들의 grad값을 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer: torch.optim.Optimizer, args):\n",
    "    if args.scheduler == \"plateau\":\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, patience=10, factor=0.5, mode=\"max\", verbose=True\n",
    "        )\n",
    "    elif args.scheduler == \"linear_warmup\":\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=args.total_steps,\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, vaild 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(logger_conf=logging_conf)\n",
    "\n",
    "def run(args,\n",
    "        train_data: np.ndarray,\n",
    "        valid_data: np.ndarray,\n",
    "        model: nn.Module):\n",
    "    train_loader, valid_loader = get_loaders(args=args, train=train_data, valid=valid_data)\n",
    "\n",
    "    # For warmup scheduler which uses step interval\n",
    "    args.total_steps = int(math.ceil(len(train_loader.dataset) / args.batch_size)) * (\n",
    "        args.n_epochs\n",
    "    )\n",
    "    args.warmup_steps = args.total_steps // 10\n",
    "\n",
    "    optimizer = get_optimizer(model=model, args=args)\n",
    "    scheduler = get_scheduler(optimizer=optimizer, args=args)\n",
    "\n",
    "    best_auc = -1\n",
    "    early_stopping_counter = 0\n",
    "    for epoch in range(args.n_epochs):\n",
    "        logger.info(\"Start Training: Epoch %s\", epoch + 1)\n",
    "\n",
    "        # TRAIN\n",
    "        train_auc, train_acc, train_loss = train(train_loader=train_loader,\n",
    "                                                 model=model, optimizer=optimizer,\n",
    "                                                 scheduler=scheduler, args=args)\n",
    "\n",
    "        # VALID\n",
    "        auc, acc = validate(valid_loader=valid_loader, model=model, args=args)\n",
    "\n",
    "        # wandb.log(dict(epoch=epoch,\n",
    "        #                train_loss_epoch=train_loss,\n",
    "        #                train_auc_epoch=train_auc,\n",
    "        #                train_acc_epoch=train_acc,\n",
    "        #                valid_auc_epoch=auc,\n",
    "        #                valid_acc_epoch=acc))\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            # nn.DataParallel로 감싸진 경우 원래의 model을 가져옵니다.\n",
    "            model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "            save_checkpoint(state={\"epoch\": epoch + 1,\n",
    "                                   \"state_dict\": model_to_save.state_dict()},\n",
    "                            model_dir=args.model_dir,\n",
    "                            model_filename=\"best_model.pt\")\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= args.patience:\n",
    "                logger.info(\n",
    "                    \"EarlyStopping counter: %s out of %s\",\n",
    "                    early_stopping_counter, args.patience\n",
    "                )\n",
    "                break\n",
    "\n",
    "        # scheduler\n",
    "        if args.scheduler == \"plateau\":\n",
    "            scheduler.step(best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state: dict, model_dir: str, model_filename: str) -> None:\n",
    "    \"\"\" Saves checkpoint to a given directory. \"\"\"\n",
    "    save_path = os.path.join(model_dir, model_filename)\n",
    "    logger.info(\"saving model as %s...\", save_path)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(state, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(preds: torch.Tensor, targets: torch.Tensor):\n",
    "    \"\"\"\n",
    "    loss계산하고 parameter update\n",
    "    Args :\n",
    "        preds   : (batch_size, max_seq_len)\n",
    "        targets : (batch_size, max_seq_len)\n",
    "\n",
    "    \"\"\"\n",
    "    loss = get_criterion(pred=preds, target=targets.float())\n",
    "\n",
    "    # 마지막 시퀀드에 대한 값만 loss 계산\n",
    "    loss = loss[:, -1]\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def get_criterion(pred: torch.Tensor, target: torch.Tensor):\n",
    "    loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    return loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(loss: torch.Tensor,\n",
    "                  model: nn.Module,\n",
    "                  optimizer: torch.optim.Optimizer,\n",
    "                  scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "                  args):\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
    "    if args.scheduler == \"linear_warmup\":\n",
    "        scheduler.step()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(targets: np.ndarray, preds: np.ndarray) -> Tuple[float]:\n",
    "    auc = roc_auc_score(y_true=targets, y_score=preds)\n",
    "    acc = accuracy_score(y_true=targets, y_pred=np.where(preds >= 0.5, 1, 0))\n",
    "    return auc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader: torch.utils.data.DataLoader,\n",
    "          model: nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "          args):\n",
    "    model.train()\n",
    "\n",
    "    total_preds = []\n",
    "    total_targets = []\n",
    "    losses = []\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
    "        preds = model(**batch)\n",
    "        targets = batch[\"correct\"]\n",
    "        \n",
    "        loss = compute_loss(preds=preds, targets=targets)\n",
    "        update_params(loss=loss, model=model, optimizer=optimizer,\n",
    "                      scheduler=scheduler, args=args)\n",
    "\n",
    "        if step % args.log_steps == 0:\n",
    "            logger.info(\"Training steps: %s Loss: %.4f\", step, loss.item())\n",
    "\n",
    "        # predictions\n",
    "        preds = sigmoid(preds[:, -1])\n",
    "        targets = targets[:, -1]\n",
    "\n",
    "        total_preds.append(preds.detach())\n",
    "        total_targets.append(targets.detach())\n",
    "        losses.append(loss)\n",
    "\n",
    "    total_preds = torch.concat(total_preds).cpu().numpy()\n",
    "    total_targets = torch.concat(total_targets).cpu().numpy()\n",
    "\n",
    "    # Train AUC / ACC\n",
    "    auc, acc = get_metric(targets=total_targets, preds=total_preds)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    logger.info(\"TRAIN AUC : %.4f ACC : %.4f\", auc, acc)\n",
    "    return auc, acc, loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader: nn.Module, model: nn.Module, args):\n",
    "    model.eval()\n",
    "\n",
    "    total_preds = []\n",
    "    total_targets = []\n",
    "    for step, batch in enumerate(valid_loader):\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
    "        preds = model(**batch)\n",
    "        targets = batch[\"correct\"]\n",
    "\n",
    "        # predictions\n",
    "        preds = sigmoid(preds[:, -1])\n",
    "        targets = targets[:, -1]\n",
    "\n",
    "        total_preds.append(preds.detach())\n",
    "        total_targets.append(targets.detach())\n",
    "\n",
    "    total_preds = torch.concat(total_preds).cpu().numpy()\n",
    "    total_targets = torch.concat(total_targets).cpu().numpy()\n",
    "\n",
    "    # Train AUC / ACC\n",
    "    auc, acc = get_metric(targets=total_targets, preds=total_preds)\n",
    "    logger.info(\"VALID AUC : %.4f ACC : %.4f\", auc, acc)\n",
    "    return auc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(args, test_data: np.ndarray, model: nn.Module) -> None:\n",
    "    model.eval()\n",
    "    _, test_loader = get_loaders(args=args, train=None, valid=test_data)\n",
    "\n",
    "    total_preds = []\n",
    "    for step, batch in enumerate(test_loader):\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
    "        preds = model(**batch)\n",
    "\n",
    "        # predictions\n",
    "        preds = sigmoid(preds[:, -1])\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "        total_preds += list(preds)\n",
    "\n",
    "    write_path = os.path.join(args.output_dir, \"submission.csv\")\n",
    "    os.makedirs(name=args.output_dir, exist_ok=True)\n",
    "    with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "        w.write(\"id,prediction\\n\")\n",
    "        for id, p in enumerate(total_preds):\n",
    "            w.write(\"{},{}\\n\".format(id, p))\n",
    "    logger.info(\"Successfully saved submission as %s\", write_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state: dict, model_dir: str, model_filename: str) -> None:\n",
    "    \"\"\" Saves checkpoint to a given directory. \"\"\"\n",
    "    save_path = os.path.join(model_dir, model_filename)\n",
    "    logger.info(\"saving model as %s...\", save_path)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(state, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    # model_path = os.path.join(args.model_dir)\n",
    "    # logger.info(\"Loading Model from: %s\", model_path)\n",
    "    # load_state = torch.load(model_path)\n",
    "    model = BERT(args) #이 부분을 내가 만든 bert를 가져오도록\n",
    "\n",
    "    # load model state\n",
    "    # model.load_state_dict(load_state[\"state_dict\"], strict=True)\n",
    "    # logger.info(\"Successfully loaded model state from: %s\", model_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login()\n",
    "\n",
    "# wandb.init(project=\"dkt\", config=vars(args))\n",
    "\n",
    "model: torch.nn.Module = load_model(args=args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-23 23:46:20,916 - root - INFO - Start Training: Epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.IntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(args, train_data, valid_data, model)\u001b[0m\n\u001b[1;32m     21\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Training: Epoch \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TRAIN\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m train_auc, train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# VALID\u001b[39;00m\n\u001b[1;32m     29\u001b[0m auc, acc \u001b[38;5;241m=\u001b[39m validate(valid_loader\u001b[38;5;241m=\u001b[39mvalid_loader, model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39margs)\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, scheduler, args)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     12\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 13\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m compute_loss(preds\u001b[38;5;241m=\u001b[39mpreds, targets\u001b[38;5;241m=\u001b[39mtargets)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[18], line 43\u001b[0m, in \u001b[0;36mBERT.forward\u001b[0;34m(self, question, tag, correct, mask, interaction)\u001b[0m\n\u001b[1;32m     41\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Embedding\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m embed_interaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_interaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m embed_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_question(question\u001b[38;5;241m.\u001b[39mint())\n\u001b[1;32m     45\u001b[0m embed_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_tag(tag\u001b[38;5;241m.\u001b[39mint())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m, in \u001b[0;36mBERTEmbedding.forward\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence):\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition(sequence)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/sparse.py:124\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1852\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m#   torch.nembedding_renorm_\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 1852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.IntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "run(args,train_data,valid_data, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
