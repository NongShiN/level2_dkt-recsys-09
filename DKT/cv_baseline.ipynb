{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09d4aa4-327c-4149-b592-68ac81c6540b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import ydata_profiling\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from math import pi\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "import json\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61dfd890-482a-41de-8faf-4f4d9dd3ff0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # 문제별 풀이시간\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df['diff_Timestamp'] = df['Timestamp'] - df.shift(1)['Timestamp']\n",
    "\n",
    "    testId_df = df[~df.duplicated(['assessmentItemID'])].groupby('testId')\n",
    "    testId2len = {}\n",
    "    for testId, g_df in testId_df:\n",
    "        testId2len[testId] = len(g_df)\n",
    "\n",
    "    userID_df = df.groupby('userID')\n",
    "    start_index_list = []\n",
    "    second_index_list = []\n",
    "\n",
    "    for userID, g_df in tqdm(userID_df):\n",
    "        testId_df = g_df.groupby('testId')\n",
    "        for testId, gg_df in testId_df:\n",
    "            index_list = gg_df.index.tolist()\n",
    "            start_index = 0\n",
    "            if len(gg_df) <= testId2len[testId]:\n",
    "                start_index_list += [index_list[start_index]]\n",
    "                second_index_list += [index_list[start_index + 1]]\n",
    "            else:\n",
    "                div = len(gg_df) // testId2len[testId]\n",
    "                for _ in range(div):\n",
    "                    start_index_list += [index_list[start_index]]\n",
    "                    second_index_list += [index_list[start_index + 1]]\n",
    "                    start_index += testId2len[testId]\n",
    "\n",
    "    df.loc[start_index_list, 'diff_Timestamp'] = df.loc[second_index_list, 'diff_Timestamp'].values\n",
    "    df['elapsed'] = df['diff_Timestamp'].apply(lambda x: x.total_seconds() if not pd.isna(x) else np.nan)\n",
    "\n",
    "\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['dow'] = df['Timestamp'].dt.dayofweek # 요일을 숫자로\n",
    "\n",
    "    diff = df.loc[:, ['userID','Timestamp']].groupby('userID').diff().fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff.fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff['Timestamp'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "    # 문제별 풀이시간\n",
    "    df['elapsed'] = diff\n",
    "    df['elapsed'] = df['elapsed'].apply(lambda x : x if x <650 and x >=0 else 0)\n",
    "\n",
    "    df['testcode']=df['testId'].apply(lambda x : int(x[1:4])//10)\n",
    "    df['problem_number'] = df['assessmentItemID'].apply(lambda x: int(x[7:])) \n",
    "\n",
    "\n",
    "    # feature 별 정답여부\n",
    "    correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_t.columns = [\"test_mean\", 'test_sum']\n",
    "    correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_k.columns = [\"tag_mean\", 'tag_sum']\n",
    "    correct_a = df.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_a.columns = [\"ass_mean\", 'ass_sum']\n",
    "    correct_p = df.groupby(['problem_number'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_p.columns = [\"prb_mean\", 'prb_sum']\n",
    "    correct_h = df.groupby(['hour'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_h.columns = [\"hour_mean\", 'hour_sum']\n",
    "    correct_d = df.groupby(['dow'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_d.columns = [\"dow_mean\", 'dow_sum'] \n",
    "\n",
    "    df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    df = pd.merge(df, correct_a, on=['assessmentItemID'], how=\"left\")\n",
    "    df = pd.merge(df, correct_p, on=['problem_number'], how=\"left\")\n",
    "    df = pd.merge(df, correct_h, on=['hour'], how=\"left\")\n",
    "    df = pd.merge(df, correct_d, on=['dow'], how=\"left\")\n",
    "\n",
    "\n",
    "    # 정답과 오답 기준으로 나눠서 생각\n",
    "    o_df = df[df['answerCode']==1]\n",
    "    x_df = df[df['answerCode']==0]\n",
    "\n",
    "    elp_k = df.groupby(['KnowledgeTag'])['elapsed'].agg('mean').reset_index()\n",
    "    elp_k.columns = ['KnowledgeTag',\"tag_elp\"]\n",
    "    elp_k_o = o_df.groupby(['KnowledgeTag'])['elapsed'].agg('mean').reset_index()\n",
    "    elp_k_o.columns = ['KnowledgeTag', \"tag_elp_o\"]\n",
    "    elp_k_x = x_df.groupby(['KnowledgeTag'])['elapsed'].agg('mean').reset_index()\n",
    "    elp_k_x.columns = ['KnowledgeTag', \"tag_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, elp_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_o, on=['KnowledgeTag'], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_x, on=['KnowledgeTag'], how=\"left\")\n",
    "\n",
    "    ass_k = df.groupby(['assessmentItemID'])['elapsed'].agg('mean').reset_index()\n",
    "    ass_k.columns = ['assessmentItemID',\"ass_elp\"]\n",
    "    ass_k_o = o_df.groupby(['assessmentItemID'])['elapsed'].agg('mean').reset_index()\n",
    "    ass_k_o.columns = ['assessmentItemID',\"ass_elp_o\"]\n",
    "    ass_k_x = x_df.groupby(['assessmentItemID'])['elapsed'].agg('mean').reset_index()\n",
    "    ass_k_x.columns = ['assessmentItemID',\"ass_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, ass_k, on=['assessmentItemID'], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_o, on=['assessmentItemID'], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_x, on=['assessmentItemID'], how=\"left\")\n",
    "\n",
    "    prb_k = df.groupby(['problem_number'])['elapsed'].agg('mean').reset_index()\n",
    "    prb_k.columns = ['problem_number',\"prb_elp\"]\n",
    "    prb_k_o = o_df.groupby(['problem_number'])['elapsed'].agg('mean').reset_index()\n",
    "    prb_k_o.columns = ['problem_number',\"prb_elp_o\"]\n",
    "    prb_k_x = x_df.groupby(['problem_number'])['elapsed'].agg('mean').reset_index()\n",
    "    prb_k_x.columns = ['problem_number',\"prb_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, prb_k, on=['problem_number'], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_o, on=['problem_number'], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_x, on=['problem_number'], how=\"left\")\n",
    "\n",
    "    # 누적합 - 주어진 데이터 이전/이후 데이터들을 포함하는 메모리를 feature로 포함시킴: Sequence Model을 사용하지 않고 일반적인 지도 학습 모델에서 사용하기 위함\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer']/df['user_total_answer']\n",
    "    df['testcode_o'] = df.groupby(['userID','testcode'])['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['testcodeCount'] = df.groupby(['userID','testcode']).cumcount()\n",
    "    df['testcodeAcc'] = df['testcode_o']/df['testcodeCount']\n",
    "    df['tectcodeElp'] = df.groupby(['userID','testcode'])['elapsed'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['testcodeMElp'] = df['tectcodeElp']/df['testcodeCount']\n",
    "\n",
    "\n",
    "\n",
    "    f = lambda x : len(set(x))\n",
    "    t_df = df.groupby(['testId']).agg({\n",
    "    'problem_number':'max',\n",
    "    'KnowledgeTag':f\n",
    "    })\n",
    "    t_df.reset_index(inplace=True)\n",
    "\n",
    "    t_df.columns = ['testId','problem_count',\"tag_count\"]\n",
    "\n",
    "    df = pd.merge(df,t_df,on='testId',how='left')\n",
    "\n",
    "    gdf = df[['userID','testId','problem_number','testcode','Timestamp']].sort_values(by=['userID','testcode','Timestamp'])\n",
    "    gdf['buserID'] = gdf['userID'] != gdf['userID'].shift(1)\n",
    "    gdf['btestcode'] = gdf['testcode'] != gdf['testcode'].shift(1)\n",
    "    gdf['first'] = gdf[['buserID','btestcode']].any(axis=1).apply(lambda x : 1- int(x))\n",
    "    gdf['RepeatedTime'] = gdf['Timestamp'].diff().fillna(pd.Timedelta(seconds=0)) \n",
    "    gdf['RepeatedTime'] = gdf['RepeatedTime'].apply(lambda x: x.total_seconds()) * gdf['first']\n",
    "    df['RepeatedTime'] = gdf['RepeatedTime'].apply(lambda x : math.log(x+1))\n",
    "\n",
    "    df['prior_KnowledgeTag_frequency'] = df.groupby(['userID','KnowledgeTag']).cumcount()\n",
    "\n",
    "    df['problem_position'] = df['problem_number'] / df[\"problem_count\"]\n",
    "    df['solve_order'] = df.groupby(['userID','testId']).cumcount()\n",
    "    df['solve_order'] = df['solve_order'] - df['problem_count']*(df['solve_order'] > df['problem_count']).apply(int) + 1\n",
    "    df['retest'] = (df['solve_order'] > df['problem_count']).apply(int)\n",
    "    T = df['solve_order'] != df['problem_number']\n",
    "    TT = T.shift(1)\n",
    "    TT[0] = False\n",
    "    df['solved_disorder'] = (TT.apply(lambda x : not x) & T).apply(int)\n",
    "\n",
    "    df['testId'] = df['testId'].apply(lambda x : int(x[1:4]+x[-3]))\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['dow'] = df['Timestamp'].dt.dayofweek\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dadee14f-b7cc-4e98-9014-682eba8f39f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('/opt/ml/level2_dkt-recsys-09/DKT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc16ae4-fc7b-481b-89f7-11125d7dd210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6698/6698 [00:20<00:00, 326.75it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "import missingno as msno\n",
    "import os\n",
    "\n",
    "DATA_PATH = '/opt/ml/input/data'\n",
    "\n",
    "%time\n",
    "dtype = {\n",
    "    'userID': 'int16',\n",
    "    'answerCode': 'int8',\n",
    "    'KnowledgeTag': 'int16'\n",
    "}   \n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'train_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "df = df.sort_values(by=['userID', 'Timestamp', 'testId']).reset_index(drop=True)\n",
    "copy_df = df.copy()\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "\n",
    "df = feature_engineering(df)\n",
    "df.to_csv(DATA_PATH + 'train_featured.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc36f2f1-6792-4099-8ced-64fe9a527efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "dtype = {\n",
    "    'userID': 'int16',\n",
    "    'answerCode': 'int8',\n",
    "    'KnowledgeTag': 'int16'\n",
    "}  \n",
    "\n",
    "DATA_PATH = '/opt/ml/input/data'\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "\n",
    "df = pd.read_csv(DATA_PATH+'train_featured.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de45b2-3862-41a6-83e7-0f868770c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: Dataset,\n",
    "            idx: list,\n",
    "            config: dict,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data[data[\"userID\"].isin(idx)]\n",
    "        self.user_list = self.data[\"userID\"].unique().tolist()\n",
    "        self.config = config\n",
    "        self.max_seq_len = config[\"dataset\"][\"max_seq_len\"]\n",
    "\n",
    "        self.Y = self.data.groupby(\"userID\")[\"answerCode\"]\n",
    "\n",
    "        self.cur_cat_col = [f\"{col}2idx\" for col in config[\"cat_cols\"]] + [\"userID\"]\n",
    "        self.cur_num_col = config[\"num_cols\"] + [\"userID\"]\n",
    "        self.X_cat = self.data.loc[:, self.cur_cat_col].copy()\n",
    "        self.X_num = self.data.loc[:, self.cur_num_col].copy()\n",
    "\n",
    "        self.X_cat = self.X_cat.groupby(\"userID\")\n",
    "        self.X_num = self.X_num.groupby(\"userID\")\n",
    "\n",
    "        self.group_data = self.data.groupby(\"userID\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        return data length\n",
    "        \"\"\"\n",
    "        return len(self.user_list)\n",
    "\n",
    "    def __getitem__(self, index: int) -> object:\n",
    "        user = self.user_list[index]\n",
    "        cat = self.X_cat.get_group(user).values[:, :-1]\n",
    "        num = self.X_num.get_group(user).values[:, :-1].astype(np.float32)\n",
    "        y = self.Y.get_group(user).values\n",
    "        seq_len = cat.shape[0]\n",
    "\n",
    "        if seq_len >= self.max_seq_len:\n",
    "            cat = torch.tensor(cat[-self.max_seq_len :], dtype=torch.long)\n",
    "            num = torch.tensor(num[-self.max_seq_len :], dtype=torch.float32)\n",
    "            y = torch.tensor(y[-self.max_seq_len :], dtype=torch.float32)\n",
    "            mask = torch.ones(self.max_seq_len, dtype=torch.long)\n",
    "        else:\n",
    "            cat = torch.cat(\n",
    "                (\n",
    "                    torch.zeros(\n",
    "                        self.max_seq_len - seq_len,\n",
    "                        len(self.cur_cat_col) - 1,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    torch.tensor(cat, dtype=torch.long),\n",
    "                )\n",
    "            )\n",
    "            num = torch.cat(\n",
    "                (\n",
    "                    torch.zeros(\n",
    "                        self.max_seq_len - seq_len,\n",
    "                        len(self.cur_num_col) - 1,\n",
    "                        dtype=torch.float32,\n",
    "                    ),\n",
    "                    torch.tensor(num, dtype=torch.float32),\n",
    "                )\n",
    "            )\n",
    "            y = torch.cat(\n",
    "                (\n",
    "                    torch.zeros(self.max_seq_len - seq_len, dtype=torch.float32),\n",
    "                    torch.tensor(y, dtype=torch.float32),\n",
    "                )\n",
    "            )\n",
    "            mask = torch.zeros(self.max_seq_len, dtype=torch.long)\n",
    "            mask[-seq_len:] = 1\n",
    "\n",
    "        return {\"cat\": cat, \"num\": num, \"answerCode\": y, \"mask\": mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a62e61b-b53c-44ca-a4b7-183c4e73ee79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------START FOLD 1 TRAINING---------------------------\n",
      "-------------------------START FOLD 1 MODEL LOADING----------------------\n",
      "(1806456, 48) (441630, 48)\n",
      "[LightGBM] [Info] Number of positive: 1181418, number of negative: 625038\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6470\n",
      "[LightGBM] [Info] Number of data points in the train set: 1806456, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653998 -> initscore=0.636658\n",
      "[LightGBM] [Info] Start training from score 0.636658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.446834\tvalid_1's binary_logloss: 0.450146\n",
      "[200]\ttraining's binary_logloss: 0.442826\tvalid_1's binary_logloss: 0.448247\n",
      "[300]\ttraining's binary_logloss: 0.44008\tvalid_1's binary_logloss: 0.447588\n",
      "[400]\ttraining's binary_logloss: 0.437808\tvalid_1's binary_logloss: 0.447161\n",
      "[500]\ttraining's binary_logloss: 0.435706\tvalid_1's binary_logloss: 0.446944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.435706\tvalid_1's binary_logloss: 0.446944\n",
      "-------------------------DONE FOLD 1 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8492506490596643 ACC : 0.7947897561306977\n",
      "\n",
      "---------------------------DONE FOLD 1 TRAINING--------------------------\n",
      "-------------------------START FOLD 2 TRAINING---------------------------\n",
      "-------------------------START FOLD 2 MODEL LOADING----------------------\n",
      "(1804088, 48) (443998, 48)\n",
      "[LightGBM] [Info] Number of positive: 1184070, number of negative: 620018\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6468\n",
      "[LightGBM] [Info] Number of data points in the train set: 1804088, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.656326 -> initscore=0.646964\n",
      "[LightGBM] [Info] Start training from score 0.646964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447169\tvalid_1's binary_logloss: 0.449072\n",
      "[200]\ttraining's binary_logloss: 0.443433\tvalid_1's binary_logloss: 0.447529\n",
      "[300]\ttraining's binary_logloss: 0.440797\tvalid_1's binary_logloss: 0.44675\n",
      "[400]\ttraining's binary_logloss: 0.438366\tvalid_1's binary_logloss: 0.446181\n",
      "[500]\ttraining's binary_logloss: 0.436214\tvalid_1's binary_logloss: 0.445973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436214\tvalid_1's binary_logloss: 0.445973\n",
      "-------------------------DONE FOLD 2 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.852706889694067 ACC : 0.7948031297438277\n",
      "\n",
      "---------------------------DONE FOLD 2 TRAINING--------------------------\n",
      "-------------------------START FOLD 3 TRAINING---------------------------\n",
      "-------------------------START FOLD 3 MODEL LOADING----------------------\n",
      "(1799078, 48) (449008, 48)\n",
      "[LightGBM] [Info] Number of positive: 1181786, number of negative: 617292\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6468\n",
      "[LightGBM] [Info] Number of data points in the train set: 1799078, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.656884 -> initscore=0.649440\n",
      "[LightGBM] [Info] Start training from score 0.649440\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.446282\tvalid_1's binary_logloss: 0.453144\n",
      "[200]\ttraining's binary_logloss: 0.442486\tvalid_1's binary_logloss: 0.451278\n",
      "[300]\ttraining's binary_logloss: 0.439729\tvalid_1's binary_logloss: 0.450553\n",
      "[400]\ttraining's binary_logloss: 0.437466\tvalid_1's binary_logloss: 0.450182\n",
      "[500]\ttraining's binary_logloss: 0.435364\tvalid_1's binary_logloss: 0.449902\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.435364\tvalid_1's binary_logloss: 0.449902\n",
      "-------------------------DONE FOLD 3 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8504228251046829 ACC : 0.792865605958023\n",
      "\n",
      "---------------------------DONE FOLD 3 TRAINING--------------------------\n",
      "-------------------------START FOLD 4 TRAINING---------------------------\n",
      "-------------------------START FOLD 4 MODEL LOADING----------------------\n",
      "(1782265, 48) (465821, 48)\n",
      "[LightGBM] [Info] Number of positive: 1167683, number of negative: 614582\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6469\n",
      "[LightGBM] [Info] Number of data points in the train set: 1782265, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655168 -> initscore=0.641834\n",
      "[LightGBM] [Info] Start training from score 0.641834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447385\tvalid_1's binary_logloss: 0.448851\n",
      "[200]\ttraining's binary_logloss: 0.443332\tvalid_1's binary_logloss: 0.44702\n",
      "[300]\ttraining's binary_logloss: 0.440696\tvalid_1's binary_logloss: 0.446494\n",
      "[400]\ttraining's binary_logloss: 0.438281\tvalid_1's binary_logloss: 0.445959\n",
      "[500]\ttraining's binary_logloss: 0.436131\tvalid_1's binary_logloss: 0.445826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436131\tvalid_1's binary_logloss: 0.445826\n",
      "-------------------------DONE FOLD 4 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8513649442001504 ACC : 0.7953999497661118\n",
      "\n",
      "---------------------------DONE FOLD 4 TRAINING--------------------------\n",
      "-------------------------START FOLD 5 TRAINING---------------------------\n",
      "-------------------------START FOLD 5 MODEL LOADING----------------------\n",
      "(1800457, 48) (447629, 48)\n",
      "[LightGBM] [Info] Number of positive: 1174663, number of negative: 625794\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1800457, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.652425 -> initscore=0.629715\n",
      "[LightGBM] [Info] Start training from score 0.629715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.448237\tvalid_1's binary_logloss: 0.445221\n",
      "[200]\ttraining's binary_logloss: 0.444305\tvalid_1's binary_logloss: 0.443485\n",
      "[300]\ttraining's binary_logloss: 0.441635\tvalid_1's binary_logloss: 0.442884\n",
      "[400]\ttraining's binary_logloss: 0.43924\tvalid_1's binary_logloss: 0.442502\n",
      "[500]\ttraining's binary_logloss: 0.437114\tvalid_1's binary_logloss: 0.442321\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.437114\tvalid_1's binary_logloss: 0.442321\n",
      "-------------------------DONE FOLD 5 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.849856271220662 ACC : 0.7973969514933126\n",
      "\n",
      "---------------------------DONE FOLD 5 TRAINING--------------------------\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "predicts_list = list()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=22)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    kf.split(train[\"userID\"].unique().tolist())\n",
    "):\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} TRAINING---------------------------\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} MODEL LOADING----------------------\"\n",
    "    )\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    \n",
    "    FEATS = train.select_dtypes(include=[\"int\", \"int8\", \"int16\", \"int64\", \"float\", \"float16\", \"float64\"]).columns\n",
    "    FEATS = [col for col in FEATS if col not in ['answerCode']]\n",
    "\n",
    "    train = df.copy()\n",
    "    x_train = train[train['userID'].isin(train_idx)]\n",
    "    x_valid = train[train['userID'].isin(val_idx)]\n",
    "    X_train, Y_train = x_train.drop(['answerCode'], axis=1), x_train['answerCode']\n",
    "    X_valid, Y_valid = x_valid.drop(['answerCode'], axis=1), x_valid['answerCode']\n",
    "    print(X_train.shape, X_valid.shape)\n",
    "\n",
    "    # Create the LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train[FEATS], Y_train)\n",
    "    lgb_test = lgb.Dataset(X_valid[FEATS], Y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=500,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"-------------------------DONE FOLD {fold + 1} MODEL LOADING-----------------------\"\n",
    "    )\n",
    "    predicts_list.append(model.predict(test_df[FEATS]))\n",
    "\n",
    "    preds = model.predict(X_valid[FEATS])\n",
    "    acc = accuracy_score(Y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(Y_valid, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    print(\n",
    "        f\"---------------------------DONE FOLD {fold + 1} TRAINING--------------------------\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4b7159c-22f7-43de-963f-3126976e4306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------START FOLD 1 TRAINING---------------------------\n",
      "-------------------------START FOLD 1 MODEL LOADING----------------------\n",
      "[LightGBM] [Info] Number of positive: 1186404, number of negative: 626864\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6468\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813268, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654290 -> initscore=0.637953\n",
      "[LightGBM] [Info] Start training from score 0.637953\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447301\tvalid_1's binary_logloss: 0.449423\n",
      "[200]\ttraining's binary_logloss: 0.443451\tvalid_1's binary_logloss: 0.44703\n",
      "[300]\ttraining's binary_logloss: 0.440961\tvalid_1's binary_logloss: 0.446065\n",
      "[400]\ttraining's binary_logloss: 0.438722\tvalid_1's binary_logloss: 0.445244\n",
      "[500]\ttraining's binary_logloss: 0.436591\tvalid_1's binary_logloss: 0.444539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436591\tvalid_1's binary_logloss: 0.444539\n",
      "-------------------------DONE FOLD 1 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8521355356441817 ACC : 0.7956445585659515\n",
      "\n",
      "---------------------------DONE FOLD 1 TRAINING--------------------------\n",
      "-------------------------START FOLD 2 TRAINING---------------------------\n",
      "-------------------------START FOLD 2 MODEL LOADING----------------------\n",
      "[LightGBM] [Info] Number of positive: 1186480, number of negative: 626789\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813269, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654332 -> initscore=0.638136\n",
      "[LightGBM] [Info] Start training from score 0.638136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447703\tvalid_1's binary_logloss: 0.448838\n",
      "[200]\ttraining's binary_logloss: 0.443957\tvalid_1's binary_logloss: 0.446421\n",
      "[300]\ttraining's binary_logloss: 0.441362\tvalid_1's binary_logloss: 0.445252\n",
      "[400]\ttraining's binary_logloss: 0.439114\tvalid_1's binary_logloss: 0.444375\n",
      "[500]\ttraining's binary_logloss: 0.436941\tvalid_1's binary_logloss: 0.443537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436941\tvalid_1's binary_logloss: 0.443537\n",
      "-------------------------DONE FOLD 2 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8530203191596302 ACC : 0.7965375223077891\n",
      "\n",
      "---------------------------DONE FOLD 2 TRAINING--------------------------\n",
      "-------------------------START FOLD 3 TRAINING---------------------------\n",
      "-------------------------START FOLD 3 MODEL LOADING----------------------\n",
      "[LightGBM] [Info] Number of positive: 1186274, number of negative: 626995\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6468\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813269, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654218 -> initscore=0.637634\n",
      "[LightGBM] [Info] Start training from score 0.637634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447817\tvalid_1's binary_logloss: 0.448363\n",
      "[200]\ttraining's binary_logloss: 0.444062\tvalid_1's binary_logloss: 0.446018\n",
      "[300]\ttraining's binary_logloss: 0.441439\tvalid_1's binary_logloss: 0.444803\n",
      "[400]\ttraining's binary_logloss: 0.439148\tvalid_1's binary_logloss: 0.443914\n",
      "[500]\ttraining's binary_logloss: 0.436969\tvalid_1's binary_logloss: 0.443149\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436969\tvalid_1's binary_logloss: 0.443149\n",
      "-------------------------DONE FOLD 3 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8531096957663562 ACC : 0.7976118257201914\n",
      "\n",
      "---------------------------DONE FOLD 3 TRAINING--------------------------\n",
      "-------------------------START FOLD 4 TRAINING---------------------------\n",
      "-------------------------START FOLD 4 MODEL LOADING----------------------\n",
      "[LightGBM] [Info] Number of positive: 1186725, number of negative: 626544\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6464\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813269, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654467 -> initscore=0.638734\n",
      "[LightGBM] [Info] Start training from score 0.638734\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447539\tvalid_1's binary_logloss: 0.449312\n",
      "[200]\ttraining's binary_logloss: 0.443752\tvalid_1's binary_logloss: 0.446995\n",
      "[300]\ttraining's binary_logloss: 0.441089\tvalid_1's binary_logloss: 0.445779\n",
      "[400]\ttraining's binary_logloss: 0.438783\tvalid_1's binary_logloss: 0.444916\n",
      "[500]\ttraining's binary_logloss: 0.436798\tvalid_1's binary_logloss: 0.444348\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436798\tvalid_1's binary_logloss: 0.444348\n",
      "-------------------------DONE FOLD 4 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8524413080836457 ACC : 0.7961801564909324\n",
      "\n",
      "---------------------------DONE FOLD 4 TRAINING--------------------------\n",
      "-------------------------START FOLD 5 TRAINING---------------------------\n",
      "-------------------------START FOLD 5 MODEL LOADING----------------------\n",
      "[LightGBM] [Info] Number of positive: 1186937, number of negative: 626332\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6464\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813269, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654584 -> initscore=0.639251\n",
      "[LightGBM] [Info] Start training from score 0.639251\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447513\tvalid_1's binary_logloss: 0.449206\n",
      "[200]\ttraining's binary_logloss: 0.443815\tvalid_1's binary_logloss: 0.446952\n",
      "[300]\ttraining's binary_logloss: 0.441151\tvalid_1's binary_logloss: 0.445772\n",
      "[400]\ttraining's binary_logloss: 0.438825\tvalid_1's binary_logloss: 0.444889\n",
      "[500]\ttraining's binary_logloss: 0.436824\tvalid_1's binary_logloss: 0.444285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436824\tvalid_1's binary_logloss: 0.444285\n",
      "-------------------------DONE FOLD 5 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8523597534206228 ACC : 0.796429430177999\n",
      "\n",
      "---------------------------DONE FOLD 5 TRAINING--------------------------\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train = df.copy()\n",
    "predicts_list = list()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=22)\n",
    "\n",
    "y_train = train['answerCode']\n",
    "train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    kf.split(train)\n",
    "):\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} TRAINING---------------------------\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} MODEL LOADING----------------------\"\n",
    "    )\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    \n",
    "    FEATS = train.select_dtypes(include=[\"int\", \"int8\", \"int16\", \"int64\", \"float\", \"float16\", \"float64\"]).columns\n",
    "    FEATS = [col for col in FEATS if col not in ['answerCode']]\n",
    "\n",
    "    X_train, Y_train = train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid, Y_valid = train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Create the LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train[FEATS], Y_train)\n",
    "    lgb_test = lgb.Dataset(X_valid[FEATS], Y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=500,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"-------------------------DONE FOLD {fold + 1} MODEL LOADING-----------------------\"\n",
    "    )\n",
    "    predicts_list.append(model.predict(test_df[FEATS]))\n",
    "\n",
    "    preds = model.predict(X_valid[FEATS])\n",
    "    acc = accuracy_score(Y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(Y_valid, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    print(\n",
    "        f\"---------------------------DONE FOLD {fold + 1} TRAINING--------------------------\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512933e-1d12-4a4b-b001-2ac02b41af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n",
    "random.seed(42)\n",
    "def custom_train_test_split(df, ratio=0.8, split=True):\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "\n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    test = df[df['userID'].isin(user_ids) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "854afb63-8e59-4e78-985d-5258e9a6bd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n",
    "def custom_K_fold_5(df): \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.seed(42)\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    train_data_div_len = 0.2*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[[] for _ in range(5)]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if sum_of_train_data < train_data_div_len:\n",
    "            user_ids[0].append(user_id)\n",
    "        elif sum_of_train_data < train_data_div_len*2:\n",
    "            user_ids[1].append(user_id)\n",
    "        elif sum_of_train_data < train_data_div_len*3:\n",
    "            user_ids[2].append(user_id)\n",
    "        elif sum_of_train_data < train_data_div_len*4:\n",
    "            user_ids[3].append(user_id)\n",
    "        else:\n",
    "            user_ids[4].append(user_id)\n",
    "            \n",
    "    final_ids =[[] for _ in range(5)]\n",
    "    for i in range(5):\n",
    "        train_idx = [x for x in df['userID'].value_counts().index if x not in user_ids[i]]\n",
    "        final_ids[i].append(train_idx)\n",
    "        final_ids[i].append(user_ids[i])\n",
    "\n",
    "    return final_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f47b5a85-abdf-4e9e-8389-319e734cefec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86ab38bc-23a2-4aca-bedf-86028be1975f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5378 1320\n",
      "5376 1322\n",
      "5363 1335\n",
      "5328 1370\n",
      "5347 1351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26792"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ids = custom_K_fold_5(df)\n",
    "a = 0\n",
    "for i in range(5):\n",
    "    a+=len(final_ids[i][0])\n",
    "    print(len(final_ids[i][0]), len(final_ids[i][1]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "742dbc57-f6b1-4583-924e-f7a750c297e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6698"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['userID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f48cdf55-a3aa-40ab-9669-40bf86018ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5378 1320\n",
      "5376 1322\n",
      "5363 1335\n",
      "5328 1370\n",
      "5347 1351\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    custom_K_fold_5(df)\n",
    "):\n",
    "    print(len(train_idx), len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaf8ff50-c8c5-4653-b91b-0e947f925dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------START FOLD 1 TRAINING---------------------------\n",
      "-------------------------START FOLD 1 MODEL LOADING----------------------\n",
      "(1813372, 48) (1320, 48)\n",
      "[LightGBM] [Info] Number of positive: 1186899, number of negative: 626473\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6465\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813372, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654526 -> initscore=0.638994\n",
      "[LightGBM] [Info] Start training from score 0.638994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447853\tvalid_1's binary_logloss: 0.487734\n",
      "[200]\ttraining's binary_logloss: 0.444086\tvalid_1's binary_logloss: 0.48404\n",
      "[300]\ttraining's binary_logloss: 0.44146\tvalid_1's binary_logloss: 0.482124\n",
      "[400]\ttraining's binary_logloss: 0.439106\tvalid_1's binary_logloss: 0.480017\n",
      "[500]\ttraining's binary_logloss: 0.437034\tvalid_1's binary_logloss: 0.478264\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.437034\tvalid_1's binary_logloss: 0.478264\n",
      "-------------------------DONE FOLD 1 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8510989378201922 ACC : 0.7606060606060606\n",
      "\n",
      "---------------------------DONE FOLD 1 TRAINING--------------------------\n",
      "-------------------------START FOLD 2 TRAINING---------------------------\n",
      "-------------------------START FOLD 2 MODEL LOADING----------------------\n",
      "(1813189, 48) (1322, 48)\n",
      "[LightGBM] [Info] Number of positive: 1187062, number of negative: 626127\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6466\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813189, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654682 -> initscore=0.639683\n",
      "[LightGBM] [Info] Start training from score 0.639683\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.44735\tvalid_1's binary_logloss: 0.507465\n",
      "[200]\ttraining's binary_logloss: 0.443495\tvalid_1's binary_logloss: 0.502348\n",
      "[300]\ttraining's binary_logloss: 0.440786\tvalid_1's binary_logloss: 0.499428\n",
      "[400]\ttraining's binary_logloss: 0.438484\tvalid_1's binary_logloss: 0.497662\n",
      "[500]\ttraining's binary_logloss: 0.436398\tvalid_1's binary_logloss: 0.497189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436398\tvalid_1's binary_logloss: 0.497189\n",
      "-------------------------DONE FOLD 2 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8352089662155944 ACC : 0.7586989409984871\n",
      "\n",
      "---------------------------DONE FOLD 2 TRAINING--------------------------\n",
      "-------------------------START FOLD 3 TRAINING---------------------------\n",
      "-------------------------START FOLD 3 MODEL LOADING----------------------\n",
      "(1813320, 48) (1335, 48)\n",
      "[LightGBM] [Info] Number of positive: 1189078, number of negative: 624242\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6468\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813320, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655746 -> initscore=0.644395\n",
      "[LightGBM] [Info] Start training from score 0.644395\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447238\tvalid_1's binary_logloss: 0.514935\n",
      "[200]\ttraining's binary_logloss: 0.443312\tvalid_1's binary_logloss: 0.511291\n",
      "[300]\ttraining's binary_logloss: 0.440435\tvalid_1's binary_logloss: 0.509183\n",
      "[400]\ttraining's binary_logloss: 0.438164\tvalid_1's binary_logloss: 0.509335\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's binary_logloss: 0.438532\tvalid_1's binary_logloss: 0.509112\n",
      "-------------------------DONE FOLD 3 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8263781474820144 ACC : 0.7445692883895131\n",
      "\n",
      "---------------------------DONE FOLD 3 TRAINING--------------------------\n",
      "-------------------------START FOLD 4 TRAINING---------------------------\n",
      "-------------------------START FOLD 4 MODEL LOADING----------------------\n",
      "(1814007, 48) (1370, 48)\n",
      "[LightGBM] [Info] Number of positive: 1181996, number of negative: 632011\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6460\n",
      "[LightGBM] [Info] Number of data points in the train set: 1814007, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.651594 -> initscore=0.626053\n",
      "[LightGBM] [Info] Start training from score 0.626053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.447994\tvalid_1's binary_logloss: 0.518134\n",
      "[200]\ttraining's binary_logloss: 0.443885\tvalid_1's binary_logloss: 0.51549\n",
      "[300]\ttraining's binary_logloss: 0.441258\tvalid_1's binary_logloss: 0.515137\n",
      "[400]\ttraining's binary_logloss: 0.438867\tvalid_1's binary_logloss: 0.514654\n",
      "[500]\ttraining's binary_logloss: 0.436872\tvalid_1's binary_logloss: 0.513904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.436872\tvalid_1's binary_logloss: 0.513904\n",
      "-------------------------DONE FOLD 4 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8245430074870687 ACC : 0.7481751824817519\n",
      "\n",
      "---------------------------DONE FOLD 4 TRAINING--------------------------\n",
      "-------------------------START FOLD 5 TRAINING---------------------------\n",
      "-------------------------START FOLD 5 MODEL LOADING----------------------\n",
      "(1812456, 48) (1351, 48)\n",
      "[LightGBM] [Info] Number of positive: 1187785, number of negative: 624671\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6467\n",
      "[LightGBM] [Info] Number of data points in the train set: 1812456, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655346 -> initscore=0.642620\n",
      "[LightGBM] [Info] Start training from score 0.642620\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.446923\tvalid_1's binary_logloss: 0.509604\n",
      "[200]\ttraining's binary_logloss: 0.442915\tvalid_1's binary_logloss: 0.508069\n",
      "[300]\ttraining's binary_logloss: 0.440315\tvalid_1's binary_logloss: 0.50769\n",
      "[400]\ttraining's binary_logloss: 0.437994\tvalid_1's binary_logloss: 0.507684\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's binary_logloss: 0.439992\tvalid_1's binary_logloss: 0.507372\n",
      "-------------------------DONE FOLD 5 MODEL LOADING-----------------------\n",
      "VALID AUC : 0.8289743814704333 ACC : 0.7572168763878608\n",
      "\n",
      "---------------------------DONE FOLD 5 TRAINING--------------------------\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "predicts_list = list()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    custom_K_fold_5(df)\n",
    "):\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} TRAINING---------------------------\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} MODEL LOADING----------------------\"\n",
    "    )\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    \n",
    "    FEATS = train.select_dtypes(include=[\"int\", \"int8\", \"int16\", \"int64\", \"float\", \"float16\", \"float64\"]).columns\n",
    "    FEATS = [col for col in FEATS if col not in ['answerCode']]\n",
    "\n",
    "    train = df.copy()\n",
    "    x_train = train[train['userID'].isin(train_idx)]\n",
    "    x_valid = train[train['userID'].isin(val_idx)]\n",
    "    x_valid = x_valid[x_valid['userID'] != x_valid['userID'].shift(-1)]\n",
    "    X_train, Y_train = x_train.drop(['answerCode'], axis=1), x_train['answerCode']\n",
    "    X_valid, Y_valid = x_valid.drop(['answerCode'], axis=1), x_valid['answerCode']\n",
    "    print(X_train.shape, X_valid.shape)\n",
    "\n",
    "    # Create the LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train[FEATS], Y_train)\n",
    "    lgb_test = lgb.Dataset(X_valid[FEATS], Y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=500,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"-------------------------DONE FOLD {fold + 1} MODEL LOADING-----------------------\"\n",
    "    )\n",
    "    predicts_list.append(model.predict(test_df[FEATS]))\n",
    "\n",
    "    preds = model.predict(X_valid[FEATS])\n",
    "    acc = accuracy_score(Y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(Y_valid, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    print(\n",
    "        f\"---------------------------DONE FOLD {fold + 1} TRAINING--------------------------\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46d2eb7e-c508-4afe-9859-1c490955d90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicts = np.mean(predicts_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e9d43ba-5e16-4ba8-b63b-bfc9bee0705b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:02<00:00, 320.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "test_df = feature_engineering(test_df)\n",
    "test_df.to_csv(DATA_PATH + 'test_featured.csv', index=False)\n",
    "\n",
    "# Inference\n",
    "test_df = pd.read_csv(DATA_PATH+'test_featured.csv')\n",
    "\n",
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "807c399c-2c4d-4454-91b8-4d76d06f03fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08924029-7ee2-429f-b080-447203b680a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAKE PREDICTION\n",
    "predicts = np.mean(predicts_list, axis=0)\n",
    "\n",
    "submission = pd.read_csv(DATA_PATH+'/sample_submission.csv')\n",
    "submission['prediction'] = predicts\n",
    "\n",
    "submission.to_csv(DATA_PATH+'/lgbm_kfold_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "860b1299-3268-4d6f-a820-6baa72a05f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005697023038779744, 0.9748787404980996)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(predicts), max(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48107d9-9a3d-4002-9a02-f952e613036e",
   "metadata": {},
   "source": [
    "## Data Augmentation 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e57ec42-164d-43ae-85cc-9ab9e4241b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def slidding_window(data, args):\n",
    "    window_size = args.max_seq_len\n",
    "    stride = args.stride\n",
    "\n",
    "    augmented_datas = []\n",
    "    for row in data:\n",
    "        seq_len = len(row[0])\n",
    "\n",
    "        # 만약 window 크기보다 seq len이 같거나 작으면 augmentation을 하지 않는다\n",
    "        if seq_len <= window_size:\n",
    "            augmented_datas.append(row)\n",
    "        else:\n",
    "            total_window = ((seq_len - window_size) // stride) + 1\n",
    "            \n",
    "            # 앞에서부터 slidding window 적용\n",
    "            for window_i in range(total_window):\n",
    "                # window로 잘린 데이터를 모으는 리스트\n",
    "                window_data = []\n",
    "                for col in row:\n",
    "                    window_data.append(col[window_i*stride:window_i*stride + window_size])\n",
    "\n",
    "                # Shuffle\n",
    "                # 마지막 데이터의 경우 shuffle을 하지 않는다\n",
    "                if args.shuffle and window_i + 1 != total_window:\n",
    "                    shuffle_datas = shuffle(window_data, window_size, args)\n",
    "                    augmented_datas += shuffle_datas\n",
    "                else:\n",
    "                    augmented_datas.append(tuple(window_data))\n",
    "\n",
    "            # slidding window에서 뒷부분이 누락될 경우 추가\n",
    "            total_len = window_size + (stride * (total_window - 1))\n",
    "            if seq_len != total_len:\n",
    "                window_data = []\n",
    "                for col in row:\n",
    "                    window_data.append(col[-window_size:])\n",
    "                augmented_datas.append(tuple(window_data))\n",
    "\n",
    "\n",
    "    return augmented_datas\n",
    "\n",
    "def shuffle(data, data_size, args):\n",
    "    shuffle_datas = []\n",
    "    for i in range(args.shuffle_n):\n",
    "        # shuffle 횟수만큼 window를 랜덤하게 계속 섞어서 데이터로 추가\n",
    "        shuffle_data = []\n",
    "        random_index = np.random.permutation(data_size)\n",
    "        for col in data:\n",
    "            shuffle_data.append(col[random_index])\n",
    "        shuffle_datas.append(tuple(shuffle_data))\n",
    "    return shuffle_datas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f8774e2-3b1d-4fc3-b3cc-bdc6748d3cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augmentation(data, args):\n",
    "    if args.window == True:\n",
    "        data = slidding_window(data, args)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2500c6fd-f80c-4d26-b1a8-40a2a667f7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easydict\n",
      "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6497 sha256=8ff65a63dc0ea8142c529f01a225b877d7a03a54893f763b3162cf9fbf4c177b\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/fe/4e/02/c9c3154e4845bfdbf1fdf344f5a89f16dcbb4f627a908c9974\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e2a0b271-c701-4a1e-9e41-67c60f93b072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "config = {}\n",
    "\n",
    "# 설정\n",
    "config['seed'] = 42\n",
    "config['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 데이터\n",
    "config['max_seq_len'] = 300\n",
    "\n",
    "# 데이터 증강 (Data Augmentation)\n",
    "config['window'] = False\n",
    "config['stride'] = 10\n",
    "config['shuffle'] = False\n",
    "config['shuffle_n'] = 2\n",
    "\n",
    "args = easydict.EasyDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c6abda4-98fa-410f-9e2c-964d8da5fc28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "0       ([600, 600, 600, 600, 600, 600, 600, 600, 600,...\n",
       "1       ([400, 400, 400, 400, 400, 400, 400, 400, 400,...\n",
       "2       ([300, 300, 300, 300, 300, 300, 300, 300, 300,...\n",
       "5       ([800, 800, 800, 800, 800, 800, 800, 800, 800,...\n",
       "6       ([300, 300, 300, 300, 300, 300, 300, 300, 300,...\n",
       "                              ...                        \n",
       "7436    ([500, 500, 500, 500, 300, 300, 300, 300, 300,...\n",
       "7437    ([400, 400, 400, 400, 400, 400, 600, 600, 600,...\n",
       "7438    ([800, 800, 800, 800, 800, 800, 401, 401, 401,...\n",
       "7440    ([500, 500, 500, 500, 500, 301, 301, 301, 301,...\n",
       "7441    ([300, 300, 300, 300, 300, 401, 401, 401, 401]...\n",
       "Length: 6698, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['userID', 'assessmentItemID', 'testId', 'answerCode', 'KnowledgeTag']\n",
    "group = df.groupby('userID').apply(\n",
    "        lambda r: (\n",
    "            r['testId'].values, \n",
    "            r['assessmentItemID'].values,\n",
    "            r['KnowledgeTag'].values,\n",
    "            r['answerCode'].values\n",
    "        )\n",
    "    )\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "37a67f78-cdbb-44e9-bd78-1146b24ca632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = df.groupby('userID')\n",
    "augmented_train_data = data_augmentation(group, args)\n",
    "if len(augmented_train_data) != len(group):\n",
    "    print(f\"Data Augmentation applied. Train data {len(group)} -> {len(augmented_train_data)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0769c773-2364-495b-ac44-71f8e4d75721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "0       ([600, 600, 600, 600, 600, 600, 600, 600, 600,...\n",
       "1       ([400, 400, 400, 400, 400, 400, 400, 400, 400,...\n",
       "2       ([300, 300, 300, 300, 300, 300, 300, 300, 300,...\n",
       "5       ([800, 800, 800, 800, 800, 800, 800, 800, 800,...\n",
       "6       ([300, 300, 300, 300, 300, 300, 300, 300, 300,...\n",
       "                              ...                        \n",
       "7436    ([500, 500, 500, 500, 300, 300, 300, 300, 300,...\n",
       "7437    ([400, 400, 400, 400, 400, 400, 600, 600, 600,...\n",
       "7438    ([800, 800, 800, 800, 800, 800, 401, 401, 401,...\n",
       "7440    ([500, 500, 500, 500, 500, 301, 301, 301, 301,...\n",
       "7441    ([300, 300, 300, 300, 300, 401, 401, 401, 401]...\n",
       "Length: 6698, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0161f8-9381-4f04-b4e6-7f0df707c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "predicts_list = list()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    custom_K_fold_5(df)\n",
    "):\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} TRAINING---------------------------\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-------------------------START FOLD {fold + 1} MODEL LOADING----------------------\"\n",
    "    )\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    \n",
    "    FEATS = train.select_dtypes(include=[\"int\", \"int8\", \"int16\", \"int64\", \"float\", \"float16\", \"float64\"]).columns\n",
    "    FEATS = [col for col in FEATS if col not in ['answerCode']]\n",
    "\n",
    "    train = df.copy()\n",
    "    x_train = train[train['userID'].isin(train_idx)]\n",
    "    x_valid = train[train['userID'].isin(val_idx)]\n",
    "    x_valid = x_valid[x_valid['userID'] != x_valid['userID'].shift(-1)]\n",
    "    X_train, Y_train = x_train.drop(['answerCode'], axis=1), x_train['answerCode']\n",
    "    X_valid, Y_valid = x_valid.drop(['answerCode'], axis=1), x_valid['answerCode']\n",
    "    print(X_train.shape, X_valid.shape)\n",
    "\n",
    "    # Create the LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train[FEATS], Y_train)\n",
    "    lgb_test = lgb.Dataset(X_valid[FEATS], Y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {'objective': 'binary'}, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_test],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=500,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"-------------------------DONE FOLD {fold + 1} MODEL LOADING-----------------------\"\n",
    "    )\n",
    "    predicts_list.append(model.predict(test_df[FEATS]))\n",
    "\n",
    "    preds = model.predict(X_valid[FEATS])\n",
    "    acc = accuracy_score(Y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(Y_valid, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    print(\n",
    "        f\"---------------------------DONE FOLD {fold + 1} TRAINING--------------------------\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
